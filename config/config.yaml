# Agentic Alzheimer's Analyzer Configuration
# ==========================================

# Dataset Configuration
dataset:
  name: "OASIS_CDR_MRI_Prediction"
  description: "OASIS dataset analysis for predicting Clinical Dementia Rating (CDR) from MRI and demographic features"
  
  # Data sources (can be paths, URLs, or other data sources)
  data_sources:
    - path: "./oasis/"
      type: "local_directory"
      description: "OASIS brain imaging and clinical data"
    # Example of multiple data sources for future experiments:
    # - path: "../additional_cohort/data/"
    #   type: "local_directory" 
    #   description: "Additional validation cohort"
    # - url: "https://api.example.com/alzheimer-data"
    #   type: "api_endpoint"
    #   description: "External validation dataset"
    # - path: "s3://bucket/alzheimer-data/"
    #   type: "cloud_storage"
    #   description: "Cloud-hosted longitudinal data"
  
  # File patterns to search for
  file_patterns:
    brain_imaging_data:
      - "oasis_cross-sectional.csv"
      - "oasis_longitudinal.csv"
      - "*oasis*.csv"
      - "*mri*.csv"
    
    clinical_data:
      - "oasis_*.csv"
      - "*clinical*.csv"
      - "*cdr*.csv"

# Research Goals and Experiment Configuration
experiment:
  name: "OASIS_CDR_MRI_Prediction_Study"
  dataset: "OASIS_CDR_MRI_Prediction"  # Links to dataset.name above
  
  primary_objectives:
    - "Predict Clinical Dementia Rating (CDR) from MRI brain imaging features"
    - "Identify most predictive MRI biomarkers for cognitive decline"
    - "Evaluate demographic factors in CDR prediction models"
    - "Compare cross-sectional vs longitudinal prediction performance"
    - "Develop interpretable CDR severity classification model"
  
  secondary_analyses:
    - "Age-stratified CDR prediction patterns"
    - "Gender differences in brain imaging biomarkers"
    - "Education effects on CDR progression"
    - "MMSE vs CDR correlation validation"
    - "Brain volume normalization impact on predictions"
  
  # Specific variables of interest (will be auto-mapped from data dictionary)
  target_variables:
    cdr_outcome: ["CDR", "cdr", "clinical_dementia_rating"]
    mri_features: ["eTIV", "nWBV", "ASF", "etiv", "nwbv", "asf"]
    demographics: ["Age", "M/F", "EDUC", "Educ", "SES", "age", "gender", "education", "ses"]
    cognitive_measures: ["MMSE", "mmse", "mini_mental"]
    brain_volumes: ["eTIV", "nWBV", "ASF", "total_intracranial_volume", "normalized_whole_brain_volume", "atlas_scaling_factor"]
    clinical_status: ["Group", "Nondemented", "Demented", "group", "diagnosis"]

# AI Configuration
ai_providers:
  # Provider preferences (in order of preference)
  preference_order: ["claude", "gemini", "openai"]
  
  claude:
    enabled: true
    api_key_env: "ANTHROPIC_API_KEY"  # Environment variable name
    default_model: "claude-3-5-sonnet-20241022"
    fallback_model: "claude-3-5-haiku-20241022"
    max_tokens: 4000
    
  openai:
    enabled: true
    api_key_env: "OPENAI_API_KEY"
    default_model: "gpt-4"
    fallback_model: "gpt-3.5-turbo"
    max_tokens: 4000
    
  gemini:
    enabled: true
    api_key_env: "GEMINI_API_KEY"
    default_model: "gemini-pro"
    max_tokens: 4000

# Discovery Configuration  
discovery:
  sample_size: 5000        # Number of rows to sample for initial discovery (if full_analysis=false)
  full_analysis: true      # Set to true to analyze complete datasets (comprehensive and accurate)
  max_files_to_analyze: 20 # Limit files analyzed for performance

# Analysis Configuration
analysis:
  # Data sampling for large datasets
  use_sampling: false         # Sample data for analysis to prevent memory issues
  analysis_sample_size: 20000 # Max rows per dataset to analyze (prevents Cartesian explosion)
  
  # Data quality thresholds
  quality_thresholds:
    min_sample_size: 100
    max_missing_percent: 50
    rt_valid_range: [0.3, 3.0]  # Valid reaction time range in seconds
    accuracy_valid_range: [0.0, 1.0]  # Valid accuracy range
  
  # Statistical analysis parameters
  statistical_settings:
    significance_level: 0.05
    effect_size_thresholds:
      small: 0.2
      medium: 0.5
      large: 0.8
    correlation_method: "pearson"  # pearson, spearman, kendall
  
  # Visualization preferences
  visualization:
    style: "publication"  # publication, presentation, web
    color_palette: "colorblind_friendly"
    figure_size: [12, 8]
    dpi: 300
    save_formats: ["png", "pdf"]

# Literature Research Configuration
literature_research:
  enabled: true
  max_papers_per_query: 20
  search_terms:
    - "CDR clinical dementia rating MRI prediction"
    - "brain imaging biomarkers cognitive decline"
    - "MRI features dementia classification"
    - "OASIS dataset CDR prediction models"
    - "brain volume normalized whole brain CDR"
    - "eTIV nWBV ASF cognitive impairment"
    - "structural MRI Alzheimer disease CDR"
  
  databases: ["pubmed", "semantic_scholar"]  # Available: pubmed, semantic_scholar, arxiv
  
  # Novelty detection thresholds
  novelty_thresholds:
    correlation_difference: 0.1  # Flag if our correlation differs by >0.1 from literature
    effect_size_difference: 0.2   # Flag if effect size differs significantly

# Output Configuration
outputs:
  base_directory: "./outputs/"
  
  # Report generation settings
  reports:
    generate_research_proposal: true
    generate_manuscript_draft: true
    generate_presentation: true
    include_raw_data_summary: false  # For privacy
  
  # Visualization settings  
  visualizations:
    create_dashboard: true
    create_individual_plots: true
    interactive_plots: true
  
  # File naming convention
  file_naming:
    timestamp: true
    experiment_name: true
    version_control: true

# Safety and Monitoring
safety:
  # Automatic stops
  max_analysis_time_hours: 6
  max_files_to_process: 50
  
  # Privacy protection
  anonymize_outputs: true
  exclude_identifiers: true
  
  # Validation checks
  validate_results: true
  cross_check_findings: true
  
# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_file: "./outputs/analysis.log"
  console_output: true
  
  # What to log
  log_token_usage: true
  log_analysis_steps: true
  log_data_access: false  # For privacy
  log_ai_interactions: true