# Agentic Alzheimer's Analyzer Configuration
# ==========================================

# Dataset Configuration
dataset:
  name: "BRFSS_Alzheimers_Healthy_Aging"
  description: "BRFSS dataset analysis for Alzheimer's Disease and Healthy Aging surveillance data"
  
  # Data sources (can be paths, URLs, or other data sources)
  data_sources:
    - path: "./training_data/brfss/"
      type: "local_directory"
      description: "BRFSS Alzheimer's Disease and Healthy Aging surveillance data"
    # Example of multiple data sources for future experiments:
    # - path: "../additional_cohort/data/"
    #   type: "local_directory" 
    #   description: "Additional validation cohort"
    # - url: "https://api.example.com/alzheimer-data"
    #   type: "api_endpoint"
    #   description: "External validation dataset"
    # - path: "s3://bucket/alzheimer-data/"
    #   type: "cloud_storage"
    #   description: "Cloud-hosted longitudinal data"
  
  # File patterns to search for
  file_patterns:
    brfss_surveillance_data:
      - "Alzheimers_Disease_And_Healthy_Aging.csv"
      - "*alzheimer*.csv"
      - "*brfss*.csv"
      - "*aging*.csv"
    
    health_data:
      - "*.csv"
      - "*health*.csv"
      - "*surveillance*.csv"

# Research Goals and Experiment Configuration
experiment:
  name: "BRFSS_Alzheimers_Surveillance_Analysis"
  dataset: "BRFSS_Alzheimers_Healthy_Aging"  # Links to dataset.name above
  
  primary_objectives:
    - "Analyze state-level patterns in Alzheimer's disease and healthy aging indicators"
    - "Identify regional variations in cognitive health outcomes"
    - "Examine temporal trends in Alzheimer's disease surveillance metrics"
    - "Correlate healthy aging indicators with Alzheimer's disease prevalence"
    - "Assess demographic and geographic risk factors"
  
  secondary_analyses:
    - "Age-stratified analysis of cognitive health indicators"
    - "State-by-state comparison of Alzheimer's disease burden"
    - "Temporal analysis of surveillance trends (2017-2020)"
    - "Social determinants of health impact on cognitive outcomes"
    - "Confidence interval analysis for surveillance estimates"
  
  # Specific variables of interest (will be auto-mapped from data dictionary)
  target_variables:
    surveillance_metrics: ["Data_Value", "Data_Value_Alt", "Data_Value_Type"]
    geographic_indicators: ["LocationAbbr", "LocationDesc", "Geolocation"]
    temporal_variables: ["YearStart", "YearEnd"]
    health_categories: ["Class", "Topic", "Question"]
    confidence_intervals: ["Low_Confidence_Limit", "High_Confidence_Limit"]
    stratification: ["StratificationCategory1", "Stratification1", "StratificationCategory2", "Stratification2"]

# AI Settings
ai_settings:
  offline_mode: false  # When true, skip external AI calls and use deterministic summaries

# AI Configuration
ai_providers:
  # Provider preferences (in order of preference)
  preference_order: ["claude", "gemini", "openai"]
  
  claude:
    enabled: true
    api_key_env: "ANTHROPIC_API_KEY"  # Environment variable name
    default_model: "claude-3-5-sonnet-20241022"
    fallback_model: "claude-3-5-haiku-20241022"
    max_tokens: 4000
    
  openai:
    enabled: true
    api_key_env: "OPENAI_API_KEY"
    default_model: "gpt-4"
    fallback_model: "gpt-3.5-turbo"
    max_tokens: 4000
    
  gemini:
    enabled: true
    api_key_env: "GEMINI_API_KEY"
    default_model: "gemini-pro"
    max_tokens: 4000

# Discovery Configuration  
discovery:
  sample_size: 5000        # Number of rows to sample for initial discovery (if full_analysis=false)
  full_analysis: true      # Set to true to analyze complete datasets (comprehensive and accurate)
  max_files_to_analyze: 20 # Limit files analyzed for performance

# Analysis Configuration
analysis:
  # Data sampling for large datasets
  use_sampling: false         # Sample data for analysis to prevent memory issues
  analysis_sample_size: 20000 # Max rows per dataset to analyze (prevents Cartesian explosion)
  
  # Data quality thresholds
  quality_thresholds:
    min_sample_size: 100
    max_missing_percent: 50
    rt_valid_range: [0.3, 3.0]  # Valid reaction time range in seconds
    accuracy_valid_range: [0.0, 1.0]  # Valid accuracy range
  
  # Statistical analysis parameters
  statistical_settings:
    significance_level: 0.05
    effect_size_thresholds:
      small: 0.2
      medium: 0.5
      large: 0.8
    correlation_method: "pearson"  # pearson, spearman, kendall
  
  # Visualization preferences
  visualization:
    style: "publication"  # publication, presentation, web
    color_palette: "colorblind_friendly"
    figure_size: [12, 8]
    dpi: 300
    save_formats: ["png", "pdf"]

# Literature Research Configuration
literature_research:
  enabled: true
  max_papers_per_query: 20
  search_terms:
    - "BRFSS Alzheimer disease surveillance data"
    - "behavioral risk factor surveillance system cognitive health"
    - "state level Alzheimer disease prevalence trends"
    - "healthy aging surveillance indicators"
    - "population based cognitive health monitoring"
    - "geographic variation Alzheimer disease burden"
    - "public health surveillance dementia trends"
  
  databases: ["pubmed", "semantic_scholar"]  # Available: pubmed, semantic_scholar, arxiv
  
  # Novelty detection thresholds
  novelty_thresholds:
    correlation_difference: 0.1  # Flag if our correlation differs by >0.1 from literature
    effect_size_difference: 0.2   # Flag if effect size differs significantly

# Output Configuration
outputs:
  base_directory: "./outputs/"
  
  # Report generation settings
  reports:
    generate_research_proposal: true
    generate_manuscript_draft: true
    generate_presentation: true
    include_raw_data_summary: false  # For privacy
  
  # Visualization settings  
  visualizations:
    create_dashboard: true
    create_individual_plots: true
    interactive_plots: true
  
  # File naming convention
  file_naming:
    timestamp: true
    experiment_name: true
    version_control: true

# Safety and Monitoring
safety:
  # Automatic stops
  max_analysis_time_hours: 6
  max_files_to_process: 50
  
  # Privacy protection
  anonymize_outputs: true
  exclude_identifiers: true
  
  # Validation checks
  validate_results: true
  cross_check_findings: true
  
# Logging Configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_file: "./outputs/analysis.log"
  console_output: true
  
  # What to log
  log_token_usage: true
  log_analysis_steps: true
  log_data_access: false  # For privacy
  log_ai_interactions: true